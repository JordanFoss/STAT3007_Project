{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "loading_samples.ipynb",
      "provenance": [],
      "mount_file_id": "1863ot8sfM3ZVamQoHqn6v_5fGbZ3b8B_",
      "authorship_tag": "ABX9TyOnPP1MdouK3L07WQoQkZbN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JordanFoss/STAT3007_Project/blob/main/loading_samples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZH8vFX56sAc",
        "outputId": "b175fd6e-5e30-4515-c1da-0bd72cfd487f"
      },
      "source": [
        "!git clone https://github.com/JordanFoss/STAT3007_Project.git\n",
        "%cd STAT3007_Project/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'STAT3007_Project'...\n",
            "remote: Enumerating objects: 3833, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 3833 (delta 41), reused 79 (delta 23), pack-reused 3722\u001b[K\n",
            "Receiving objects: 100% (3833/3833), 673.58 MiB | 26.27 MiB/s, done.\n",
            "Resolving deltas: 100% (626/626), done.\n",
            "Checking out files: 100% (2827/2827), done.\n",
            "/content/STAT3007_Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L9Nuff46_aI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM7RFopO64II"
      },
      "source": [
        "import librosa\n",
        "from librosa import display\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from IPython.display import Audio\n",
        "import glob\n",
        "from pre_process import *\n",
        "import os\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import scipy\n",
        "from torchsummary import summary"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVDmhvD_7Mt9"
      },
      "source": [
        "# load our own python files\n",
        "import pre_process\n",
        "import data_loading"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJv7nEZdY5UA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbaNzBb07bGd"
      },
      "source": [
        "# Loading all the noisy sampels we have"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36Njz5j97T_v"
      },
      "source": [
        "# path to the noisy samples on drive\n",
        "model_folder = '/content/drive/MyDrive/STAT3007 project/Noisy_samples_to_train_for_seminar'\n",
        "X, y = data_loading.load_noisy_samples(model_folder)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNqClHxtS1PJ"
      },
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBJVNeB4TnOa"
      },
      "source": [
        "# Save to file\n",
        "np.save('/content/drive/MyDrive/STAT3007 project/noisy_spectrograms_complete.npy',X)\n",
        "np.save('/content/drive/MyDrive/STAT3007 project/noisy_targets_complete.npy',y)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrZgBGJEZ3zH"
      },
      "source": [
        "# loading the data again\n",
        "X = np.load('/content/drive/MyDrive/STAT3007 project/noisy_spectrograms_complete.npy')\n",
        "y = np.load('/content/drive/MyDrive/STAT3007 project/noisy_targets_complete.npy')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ0YYRK2AGMA"
      },
      "source": [
        "# Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZNX_faj7wFB"
      },
      "source": [
        "# data_sets contain two paires of data_train, data_test.\n",
        "# the second pair of train/test set is split from the test set from the first one\n",
        "\n",
        "# reshape it properly, then chuck it in\n",
        "X = torch.tensor(X).reshape(X.shape[0],1,X.shape[1],X.shape[2])\n",
        "y = torch.tensor(y)\n",
        "\n",
        "data_sets = data_loading.load_sets(X,y, train_ratio = [0.7,0.7], seed = [10,11])\n",
        "\n",
        "# output [(data_train,data_test),(data_train,data_test)]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}