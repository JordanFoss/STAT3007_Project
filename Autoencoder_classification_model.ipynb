{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNA9G2HMMY7/8yIIJst05kq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JordanFoss/STAT3007_Project/blob/main/Autoencoder_classification_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc_2bo5crxzH",
        "outputId": "e3bd0426-85c9-4aea-d456-f7b4433d3333"
      },
      "source": [
        "!git clone https://github.com/JordanFoss/STAT3007_Project.git\n",
        "%cd STAT3007_Project/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'STAT3007_Project'...\n",
            "remote: Enumerating objects: 3888, done.\u001b[K\n",
            "remote: Counting objects: 100% (166/166), done.\u001b[K\n",
            "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
            "remote: Total 3888 (delta 67), reused 110 (delta 32), pack-reused 3722\u001b[K\n",
            "Receiving objects: 100% (3888/3888), 676.10 MiB | 16.85 MiB/s, done.\n",
            "Resolving deltas: 100% (652/652), done.\n",
            "Checking out files: 100% (2839/2839), done.\n",
            "/content/STAT3007_Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlhFyxs2K434"
      },
      "source": [
        "import librosa\n",
        "from librosa import display\n",
        "import torch\n",
        "import numpy as np\n",
        "from IPython.display import Audio\n",
        "import glob\n",
        "from pre_process import *\n",
        "import os\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import scipy\n",
        "from torchsummary import summary\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "import numpy as np\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUpErU31d80Z"
      },
      "source": [
        "# Denoising Autoencoder architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBsyywF6douQ"
      },
      "source": [
        "# Autoencoder with optimal hyper-parameters already put in\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, filters = 8):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.conv = nn.Sequential(nn.Conv2d(1, filters, kernel_size= (3,4), stride = 1),\n",
        "                              nn.ReLU(),\n",
        "                              nn.MaxPool2d(kernel_size = 2),\n",
        "                              nn.ReLU(),\n",
        "                              nn.Conv2d(filters,filters,kernel_size= (3,4), stride = 1),\n",
        "                              nn.ReLU(),\n",
        "                              nn.MaxPool2d(kernel_size = 2),\n",
        "                              nn.Conv2d(filters,filters,kernel_size= (3,4), stride = 1),\n",
        "                              nn.ReLU()\n",
        "                              )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, filters = 8):\n",
        "    super(Decoder, self).__init__()\n",
        "    (K, S) = (2, 1)\n",
        "    self.conv = nn.Sequential(nn.ConvTranspose2d(filters,filters, kernel_size = (3,4)),\n",
        "                              nn.ReLU(),\n",
        "                              nn.Upsample(size = (61,27)),\n",
        "                              nn.ConvTranspose2d(filters,filters, kernel_size = (3,4)),\n",
        "                              nn.ReLU(),\n",
        "                              nn.Upsample(size = (126,60)),\n",
        "                              nn.ConvTranspose2d(filters,1, kernel_size = (3,4)),\n",
        "                              )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return x\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self, filters = 8):\n",
        "    super(Autoencoder,self).__init__()\n",
        "    self.filters = filters\n",
        "    self.encoder = Encoder(filters)\n",
        "    self.decoder = Decoder(filters)\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = self.decoder(x)\n",
        "    return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-04BvJmUfQPB",
        "outputId": "4b0cf37f-2c66-473c-88ec-5395024dc902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "summary(Autoencoder().cuda(), (1,128,63))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 8, 126, 60]             104\n",
            "              ReLU-2           [-1, 8, 126, 60]               0\n",
            "         MaxPool2d-3            [-1, 8, 63, 30]               0\n",
            "              ReLU-4            [-1, 8, 63, 30]               0\n",
            "            Conv2d-5            [-1, 8, 61, 27]             776\n",
            "              ReLU-6            [-1, 8, 61, 27]               0\n",
            "         MaxPool2d-7            [-1, 8, 30, 13]               0\n",
            "            Conv2d-8            [-1, 8, 28, 10]             776\n",
            "              ReLU-9            [-1, 8, 28, 10]               0\n",
            "          Encoder-10            [-1, 8, 28, 10]               0\n",
            "  ConvTranspose2d-11            [-1, 8, 30, 13]             776\n",
            "             ReLU-12            [-1, 8, 30, 13]               0\n",
            "         Upsample-13            [-1, 8, 61, 27]               0\n",
            "  ConvTranspose2d-14            [-1, 8, 63, 30]             776\n",
            "             ReLU-15            [-1, 8, 63, 30]               0\n",
            "         Upsample-16           [-1, 8, 126, 60]               0\n",
            "  ConvTranspose2d-17           [-1, 1, 128, 63]              97\n",
            "          Decoder-18           [-1, 1, 128, 63]               0\n",
            "================================================================\n",
            "Total params: 3,305\n",
            "Trainable params: 3,305\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 2.39\n",
            "Params size (MB): 0.01\n",
            "Estimated Total Size (MB): 2.44\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkZxJgbueC2Q"
      },
      "source": [
        "# Classification Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Irby8hekeGuF"
      },
      "source": [
        "## 1. CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jTo8cCJeNik"
      },
      "source": [
        "# input: batch_sizex8x28x10\n",
        "#output: batch_sizex5\n",
        "class ConvClassification(nn.Module):\n",
        "    def __init__(self, input_channel,contain_linear = False, filter_num = 6):\n",
        "        super(ConvClassification, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.conv1 = nn.Conv2d(input_channel, filter_num, kernel_size = (2,3))\n",
        "        self.conv2 = nn.Sequential(nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(1,2), stride = 2),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Conv2d(filter_num, 4, kernel_size = (2,3)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(1,2), stride = 2),\n",
        "        )\n",
        "\n",
        "        self.contain_linear = contain_linear\n",
        "\n",
        "        if contain_linear:\n",
        "          self.linear = nn.Sequential(\n",
        "              nn.Linear(4*7, 10),\n",
        "              nn.Linear(10, 5),\n",
        "          )\n",
        "\n",
        "    def forward(self, x, inspect_feature = False):\n",
        "\n",
        "      first_layer = self.conv1(x)\n",
        "      conv_x = self.conv2(first_layer)\n",
        "\n",
        "      output_x = conv_x\n",
        "      if self.contain_linear:\n",
        "        conv_x_flat  = self.flatten(conv_x)\n",
        "        output_x = self.linear(conv_x_flat)\n",
        "      \n",
        "      if inspect_feature:\n",
        "        return first_layer,conv_x,output_x\n",
        "      return output_x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4ATAGxcgANa",
        "outputId": "761d03b8-834a-458b-ff15-e07406051d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "summary(ConvClassification(8, contain_linear= True).cuda(),(8,28,10))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1             [-1, 6, 27, 8]             294\n",
            "              ReLU-2             [-1, 6, 27, 8]               0\n",
            "         MaxPool2d-3             [-1, 6, 14, 4]               0\n",
            "           Dropout-4             [-1, 6, 14, 4]               0\n",
            "            Conv2d-5             [-1, 4, 13, 2]             148\n",
            "              ReLU-6             [-1, 4, 13, 2]               0\n",
            "         MaxPool2d-7              [-1, 4, 7, 1]               0\n",
            "           Flatten-8                   [-1, 28]               0\n",
            "            Linear-9                   [-1, 10]             290\n",
            "           Linear-10                    [-1, 5]              55\n",
            "================================================================\n",
            "Total params: 787\n",
            "Trainable params: 787\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.03\n",
            "Params size (MB): 0.00\n",
            "Estimated Total Size (MB): 0.04\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY1SVEQ_jLFJ"
      },
      "source": [
        "## 2. FC Linear network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I9FMpgTjP-j"
      },
      "source": [
        "class LinearClassification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LinearClassification, self).__init__()\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear = nn.Sequential(nn.Linear(8*28*10, 1024),\n",
        "                                nn.Sigmoid(),\n",
        "                                nn.Linear(1024,5))\n",
        "    \n",
        "  def forward(self,x):\n",
        "    x_flat = self.flatten(x)\n",
        "\n",
        "    pred = self.linear(x_flat)\n",
        "\n",
        "    return pred\n",
        "    "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILkNacYMnpne",
        "outputId": "2d8935b8-5758-4b8f-dd2f-c000867eef1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "summary(LinearClassification().cuda(),(8,28,10))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "           Flatten-1                 [-1, 2240]               0\n",
            "            Linear-2                 [-1, 1024]       2,294,784\n",
            "           Sigmoid-3                 [-1, 1024]               0\n",
            "            Linear-4                    [-1, 5]           5,125\n",
            "================================================================\n",
            "Total params: 2,299,909\n",
            "Trainable params: 2,299,909\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.03\n",
            "Params size (MB): 8.77\n",
            "Estimated Total Size (MB): 8.81\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrLvPwvioG6m"
      },
      "source": [
        "## 3. Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EMTDZ1OoP5L"
      },
      "source": [
        "\n",
        "# building a naive bayes classifier\n",
        "def classification_model(X_train,y_train, X_test, y_test):\n",
        "  NB = MultinomialNB()\n",
        "  NB.fit(X_train,y_train)\n",
        "  y_pred = NB.predict(X_test)\n",
        "\n",
        "  # metrics\n",
        "  # count correctly classified samples\n",
        "  correct_count = np.count_nonzero(y_pred == y_test)\n",
        "  accuracy = metrics.accuracy_score(y_test,y_pred)\n",
        "  balanced_accuracy = metrics.balanced_accuracy_score(y_test,y_pred)\n",
        "\n",
        "  print('total sample counts:',y_pred.shape[0])\n",
        "  print('correct classification counts:',correct_count,'(',accuracy * 100,'%)')\n",
        "  print('{0}: {1:.1%}'.format('balanced accuracy', balanced_accuracy))\n",
        "  print('misclasification counts:',y_pred.shape[0] - correct_count,'(',(1 - accuracy)*100,'%)')\n",
        "\n",
        "  return NB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S39iQupwB1Bj"
      },
      "source": [
        "# next step: training procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DJDYjiBogCs"
      },
      "source": [
        "spectro_data = DatasetWrapper(X,y)\n",
        "train_size = int(X.shape[0] * 0.7)\n",
        "test_size = X.shape[0] - train_size\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "data_test, data_train = random_split(spectro_data,[test_size,train_size], generator = torch.Generator().manual_seed(10))\n",
        "nepoch = 100\n",
        "batch_size = 30\n",
        "\n",
        "torch.manual_seed(69)\n",
        "AE = Autoencoder()\n",
        "\n",
        "trained_net = train_model(data_train,AE, loss, nepoch = nepoch,lr = 0.01, batch_size = batch_size, use_cuda = True,print_output = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yige6Md_Lora"
      },
      "source": [
        "Xc = []\n",
        "yc = []\n",
        "target_map = {'02':0,'03':1,'04':2,'05':3,'08':4}\n",
        "\n",
        "for file in glob.glob(os.getcwd() + '/sample-noisy-speech-actor-11/*.wav'):\n",
        "  name = file.split('/')[-1]\n",
        "  emotion = name.split('-')[0]\n",
        "\n",
        "  samples, sampling_rate = librosa.load(file, sr = 16000)\n",
        "  spec = data_gen(samples, sampling_rate, 2)\n",
        "\n",
        "  Xc.append(spec)\n",
        "  yc.append(target_map[emotion])\n",
        "\n",
        "Xc = torch.tensor(Xc)\n",
        "Xc = Xc.reshape(Xc.shape[0],1,Xc.shape[1],Xc.shape[2])\n",
        "\n",
        "X_feature = feature_net.to(torch.device('cpu'))(Xc)\n",
        "\n",
        "yc = torch.tensor(yc)\n",
        "yc = yc.type(torch.LongTensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9hErwFZsB7i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tkyz_nrqZcK"
      },
      "source": [
        "X_feature = torch.tensor(X_feature.detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zYJzfvFO2jG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4afa883c-89c4-4679-f255-26a844daa24c"
      },
      "source": [
        "classification_data = DatasetWrapper(X_feature,yc)\n",
        "train_size = int(X_feature.shape[0] * 0.7)\n",
        "test_size = X_feature.shape[0] - train_size\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "data_test, data_train = random_split(classification_data,[test_size,train_size], generator = torch.Generator().manual_seed(10))\n",
        "nepoch = 100\n",
        "batch_size = 30\n",
        "\n",
        "torch.manual_seed(69)\n",
        "CNN = ConvNet(input_channel = 16, contain_linear= True).cuda()\n",
        "\n",
        "\n",
        "\n",
        "trained_net = train_model(data_train,CNN, loss, nepoch = nepoch,lr = 0.01, batch_size = batch_size, use_cuda = True,print_output = True, classification = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "loss: 6.794913929297763e-07\n",
            "------------\n",
            "epoch: 1\n",
            "loss: 0.6743510961532593\n",
            "------------\n",
            "epoch: 2\n",
            "loss: 0.0003673128376249224\n",
            "------------\n",
            "epoch: 3\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 4\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 5\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 6\n",
            "loss: 12.359458923339844\n",
            "------------\n",
            "epoch: 7\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 8\n",
            "loss: 16.698596954345703\n",
            "------------\n",
            "epoch: 9\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 10\n",
            "loss: 72.20507049560547\n",
            "------------\n",
            "epoch: 11\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 12\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 13\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 14\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 15\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 16\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 17\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 18\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 19\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 20\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 21\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 22\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 23\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 24\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 25\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 26\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 27\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 28\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 29\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 30\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 31\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 32\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 33\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 34\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 35\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 36\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 37\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 38\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 39\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 40\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 41\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 42\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 43\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 44\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 45\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 46\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 47\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 48\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 49\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 50\n",
            "loss: 86.2164077758789\n",
            "------------\n",
            "epoch: 51\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 52\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 53\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 54\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 55\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 56\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 57\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 58\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 59\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 60\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 61\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 62\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 63\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 64\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 65\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 66\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 67\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 68\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 69\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 70\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 71\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 72\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 73\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 74\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 75\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 76\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 77\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 78\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 79\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 80\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 81\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 82\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 83\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 84\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 85\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 86\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 87\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 88\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 89\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 90\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 91\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 92\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 93\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 94\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 95\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 96\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 97\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 98\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 99\n",
            "loss: 1291.1483154296875\n",
            "------------\n",
            "final loss: 1291.1483154296875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krn0DTnkvfMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de8957d-923d-4c16-d8df-a2d524f236a9"
      },
      "source": [
        "X_feature.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([790, 16, 28, 12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua8j5KhqwLGX"
      },
      "source": [
        "X_feature_flat = torch.flatten(X_feature,start_dim = 1)\n",
        "classification_data = DatasetWrapper(X_feature_flat,yc)\n",
        "train_size = int(X_feature.shape[0] * 0.7)\n",
        "test_size = X_feature.shape[0] - train_size\n",
        "\n",
        "data_test, data_train = random_split(classification_data,[test_size,train_size], generator = torch.Generator().manual_seed(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiJ3BXfYviPj"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "# building a naive bayes classifier\n",
        "def classification_model(X_train,y_train, X_test, y_test):\n",
        "  NB = MultinomialNB()\n",
        "  NB.fit(X_train,y_train)\n",
        "  y_pred = NB.predict(X_test)\n",
        "\n",
        "  # metrics\n",
        "  # count correctly classified samples\n",
        "  correct_count = np.count_nonzero(y_pred == y_test)\n",
        "  accuracy = metrics.accuracy_score(y_test,y_pred)\n",
        "  balanced_accuracy = metrics.balanced_accuracy_score(y_test,y_pred)\n",
        "\n",
        "  print('total sample counts:',y_pred.shape[0])\n",
        "  print('correct classification counts:',correct_count,'(',accuracy * 100,'%)')\n",
        "  print('{0}: {1:.1%}'.format('balanced accuracy', balanced_accuracy))\n",
        "  print('misclasification counts:',y_pred.shape[0] - correct_count,'(',(1 - accuracy)*100,'%)')\n",
        "\n",
        "  return NB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4eJW9Ufvo9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74e03889-a27b-4560-f24b-c526baab7917"
      },
      "source": [
        "training_pixel_feature,training_pixel_target = data_train.dataset.get_data()\n",
        "test_pixel_feature,test_pixel_target = data_test.dataset.get_data()\n",
        "\n",
        "\n",
        "NB_pixel = classification_model(training_pixel_feature.detach().numpy(),training_pixel_target.detach().numpy(),test_pixel_feature.detach().numpy(),test_pixel_target.detach().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total sample counts: 790\n",
            "correct classification counts: 783 ( 99.1139240506329 %)\n",
            "balanced accuracy: 99.1%\n",
            "misclasification counts: 7 ( 0.8860759493670933 %)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtpjARXtyIl6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}