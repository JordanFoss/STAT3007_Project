{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conv_LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOWireDVFVIT96Ey3wPyajv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JordanFoss/STAT3007_Project/blob/main/Conv_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZWQb0ebc-fP",
        "outputId": "109caff9-44ce-484f-96fb-661b1987526b"
      },
      "source": [
        "!git clone https://github.com/JordanFoss/STAT3007_Project.git\n",
        "%cd STAT3007_Project/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'STAT3007_Project'...\n",
            "remote: Enumerating objects: 3982, done.\u001b[K\n",
            "remote: Counting objects: 100% (260/260), done.\u001b[K\n",
            "remote: Compressing objects: 100% (209/209), done.\u001b[K\n",
            "remote: Total 3982 (delta 114), reused 168 (delta 49), pack-reused 3722\u001b[K\n",
            "Receiving objects: 100% (3982/3982), 677.11 MiB | 31.63 MiB/s, done.\n",
            "Resolving deltas: 100% (699/699), done.\n",
            "Checking out files: 100% (2855/2855), done.\n",
            "/content/STAT3007_Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEw6Ckz2dADM"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms import ToTensor\n",
        "import scipy\n",
        "import numpy as np\n",
        "import librosa\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "from librosa import display\n",
        "from torchsummary import summary\n",
        "\n",
        "from IPython.display import Audio"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0LO_f7TdtXz",
        "outputId": "a0245eab-8683-4c57-c624-3b3f1c88bfcd"
      },
      "source": [
        "!pip install colorednoise as cn"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting colorednoise\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/3e/85645bcaa5ba6003c6e3c650fe23c6352f7aa4a36eb1d700f3609e52963e/colorednoise-1.1.1.tar.gz\n",
            "Collecting as\n",
            "  Downloading https://files.pythonhosted.org/packages/b4/08/226c133ec497d25a63edb38527c02db093c7d89e6d4cdc91078834486a5d/as-0.1-py3-none-any.whl\n",
            "Collecting cn\n",
            "  Downloading https://files.pythonhosted.org/packages/d2/f0/37acf3f62cd9311fe8f9b373cacd77ce2ab131bc138615e7ccec8d9d793a/cn-0.0.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from colorednoise) (1.19.5)\n",
            "Building wheels for collected packages: colorednoise\n",
            "  Building wheel for colorednoise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colorednoise: filename=colorednoise-1.1.1-cp37-none-any.whl size=3958 sha256=f3b42fe4e637d6bef06b8f5fe89102f587fafa13856f25fdecf4b1480591546f\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/be/f3/3e7e1c80ebab3f6f0dbd3e34e787b902d2280d66706485fef4\n",
            "Successfully built colorednoise\n",
            "Installing collected packages: colorednoise, as, cn\n",
            "Successfully installed as-0.1 cn-0.0.0.0 colorednoise-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXPrJdoQdBoF"
      },
      "source": [
        "import pre_process\n",
        "import data_loading\n",
        "import CNN_Model\n",
        "from data_loading import *"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nVTA7Undqxc"
      },
      "source": [
        "X,y = data_loading.load_samples(os.getcwd())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT0Z8Azqmk5w"
      },
      "source": [
        "X = torch.tensor(X)\n",
        "X = X.reshape(X.shape[0],1,X.shape[1],X.shape[2])\n",
        "y = torch.tensor(y)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_aDV5To1Zrl",
        "outputId": "acb4b292-b6cb-43eb-af2e-256f4a95acd5"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([480, 1, 128, 63])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExITYlk_fHvl"
      },
      "source": [
        "cnn = CNN_Model.ConvNet()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsFFMnZGlnNY",
        "outputId": "84e4c65c-9252-41e4-9b55-b54a9aeda9ed"
      },
      "source": [
        "summary(cnn.cuda(), (1,128,21))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 14, 127, 19]              98\n",
            "              ReLU-2          [-1, 14, 127, 19]               0\n",
            "         MaxPool2d-3            [-1, 14, 64, 9]               0\n",
            "           Dropout-4            [-1, 14, 64, 9]               0\n",
            "            Conv2d-5            [-1, 24, 63, 7]           2,040\n",
            "              ReLU-6            [-1, 24, 63, 7]               0\n",
            "         MaxPool2d-7            [-1, 24, 32, 3]               0\n",
            "================================================================\n",
            "Total params: 2,138\n",
            "Trainable params: 2,138\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.82\n",
            "Params size (MB): 0.01\n",
            "Estimated Total Size (MB): 0.84\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv8lw7Y2mixF"
      },
      "source": [
        "# RNN combined with CNN\n",
        "class LRCN(nn.Module):\n",
        "    def __init__(self, CNN, shape = (24,32,3)):\n",
        "        super(LRCN, self).__init__()\n",
        "\n",
        "        self.cnn = CNN\n",
        "        self.shape = shape\n",
        "\n",
        "        channel, freq, times = shape\n",
        "        self.lstm_layers = nn.LSTM(freq*channel*times,256,num_layers = 2, bidirectional = True)\n",
        "        self.linear = nn.Sequential(nn.Linear(256*2, 5))\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x, step_size = 21, use_cuda = False):\n",
        "\n",
        "      if use_cuda:\n",
        "        h_t = torch.zeros(4,x.shape[0] ,256, dtype=torch.float).to(x.device)\n",
        "        c_t = torch.zeros(4,x.shape[0], 256, dtype=torch.float).to(x.device)\n",
        "\n",
        "      else:\n",
        "        h_t = torch.zeros(4,x.shape[0], 256, dtype=torch.float)\n",
        "        c_t = torch.zeros(4,x.shape[0], 256, dtype=torch.float)\n",
        "      \n",
        "      look_ahead_time = 21\n",
        "      for current_time in range(0,x.shape[-1], step_size):\n",
        "\n",
        "        x_t = x[:,:,:,current_time:current_time+look_ahead_time]\n",
        "        conv_x = self.cnn(x_t)\n",
        "\n",
        "        conv_x_flat =  self.flatten(conv_x)\n",
        "\n",
        "        conv_x_flat = conv_x_flat.reshape(1,conv_x_flat.shape[0],conv_x_flat.shape[1])\n",
        "\n",
        "        output, (h_t, c_t) = self.lstm_layers(conv_x_flat, (h_t, c_t))\n",
        "\n",
        "      decision_vec = self.linear(output[0])\n",
        "      return decision_vec"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWF9B5IYuAWl"
      },
      "source": [
        "conv_LSTM = LRCN(cnn)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTScXLjNuuMO"
      },
      "source": [
        "data_sets = data_loading.load_sets(X,y,train_ratio=[0.8], seed = [10])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxpGLfOqvcVJ"
      },
      "source": [
        "data_train, data_test = data_sets[0]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmwjVjoKvdR6"
      },
      "source": [
        "def train_model(data_train, data_test, net, loss, nepoch ,lr = 0.01, batch_size = -1, use_cuda = False, print_output = True):\n",
        "\n",
        "  # appropriate data type for CPU or GPU\n",
        "  device = None\n",
        "  if use_cuda and torch.cuda.is_available():\n",
        "    dtype = torch.cuda.FloatTensor\n",
        "    device = torch.device(\"cuda\")\n",
        "    net = net.to(device)\n",
        "  else:\n",
        "    dtype = torch.FloatTensor\n",
        "\n",
        "  optimizer = optim.SGD(net.parameters(), lr = lr)\n",
        "  data_train = data_train.change_type(dtype)\n",
        "  data_test = data_test.change_type(dtype)\n",
        "\n",
        "  data_loader = DataLoader(data_train, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "  for epoch in range(nepoch):\n",
        "    for X_batch, y_batch in data_loader:\n",
        "      y_batch = y_batch.type(torch.LongTensor)\n",
        "      if use_cuda and device != None:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        y_batch = y_batch.type(torch.cuda.LongTensor)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # since all our values are negative, we convert them to positive\n",
        "\n",
        "\n",
        "      pred = net(X_batch, use_cuda = use_cuda)\n",
        "      Rn = loss(pred, y_batch)\n",
        "      Rn.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    if print_output:\n",
        "      print('epoch:', epoch)\n",
        "      print('loss:',Rn.item())\n",
        "      print('------------')\n",
        "\n",
        "  print('final loss:', Rn.item())\n",
        "\n",
        "  return net"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0csDbqOv8Fx"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS26mkHXwHpC",
        "outputId": "114fd157-83c1-467d-b6ef-bae7117446dd"
      },
      "source": [
        "nepoch = 100\n",
        "trained_net = train_model(data_train, data_test, conv_LSTM, loss, nepoch=nepoch , batch_size = 10,lr = 0.01, use_cuda = True, print_output = True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "loss: 1.5841327905654907\n",
            "------------\n",
            "epoch: 1\n",
            "loss: 1.59458327293396\n",
            "------------\n",
            "epoch: 2\n",
            "loss: 1.4534306526184082\n",
            "------------\n",
            "epoch: 3\n",
            "loss: 1.494640827178955\n",
            "------------\n",
            "epoch: 4\n",
            "loss: 1.5227930545806885\n",
            "------------\n",
            "epoch: 5\n",
            "loss: 1.3978391885757446\n",
            "------------\n",
            "epoch: 6\n",
            "loss: 1.3122608661651611\n",
            "------------\n",
            "epoch: 7\n",
            "loss: 1.377127766609192\n",
            "------------\n",
            "epoch: 8\n",
            "loss: 1.1024502515792847\n",
            "------------\n",
            "epoch: 9\n",
            "loss: 1.208505392074585\n",
            "------------\n",
            "epoch: 10\n",
            "loss: 1.0481246709823608\n",
            "------------\n",
            "epoch: 11\n",
            "loss: 1.2226552963256836\n",
            "------------\n",
            "epoch: 12\n",
            "loss: 1.284131646156311\n",
            "------------\n",
            "epoch: 13\n",
            "loss: 1.3064134120941162\n",
            "------------\n",
            "epoch: 14\n",
            "loss: 1.2983156442642212\n",
            "------------\n",
            "epoch: 15\n",
            "loss: 0.9761627316474915\n",
            "------------\n",
            "epoch: 16\n",
            "loss: 1.3816237449645996\n",
            "------------\n",
            "epoch: 17\n",
            "loss: 0.8816111087799072\n",
            "------------\n",
            "epoch: 18\n",
            "loss: 1.320134162902832\n",
            "------------\n",
            "epoch: 19\n",
            "loss: 0.9197540879249573\n",
            "------------\n",
            "epoch: 20\n",
            "loss: 0.9899702072143555\n",
            "------------\n",
            "epoch: 21\n",
            "loss: 1.265564203262329\n",
            "------------\n",
            "epoch: 22\n",
            "loss: 0.7720962762832642\n",
            "------------\n",
            "epoch: 23\n",
            "loss: 0.5599398016929626\n",
            "------------\n",
            "epoch: 24\n",
            "loss: 1.3068339824676514\n",
            "------------\n",
            "epoch: 25\n",
            "loss: 0.46505969762802124\n",
            "------------\n",
            "epoch: 26\n",
            "loss: 1.0006709098815918\n",
            "------------\n",
            "epoch: 27\n",
            "loss: 1.0912184715270996\n",
            "------------\n",
            "epoch: 28\n",
            "loss: 0.5539417862892151\n",
            "------------\n",
            "epoch: 29\n",
            "loss: 0.3846088945865631\n",
            "------------\n",
            "epoch: 30\n",
            "loss: 0.5633492469787598\n",
            "------------\n",
            "epoch: 31\n",
            "loss: 0.7964868545532227\n",
            "------------\n",
            "epoch: 32\n",
            "loss: 0.4560604989528656\n",
            "------------\n",
            "epoch: 33\n",
            "loss: 0.5224940776824951\n",
            "------------\n",
            "epoch: 34\n",
            "loss: 0.6173474192619324\n",
            "------------\n",
            "epoch: 35\n",
            "loss: 1.3575655221939087\n",
            "------------\n",
            "epoch: 36\n",
            "loss: 0.8022533059120178\n",
            "------------\n",
            "epoch: 37\n",
            "loss: 0.58733069896698\n",
            "------------\n",
            "epoch: 38\n",
            "loss: 0.4164116084575653\n",
            "------------\n",
            "epoch: 39\n",
            "loss: 0.2268206775188446\n",
            "------------\n",
            "epoch: 40\n",
            "loss: 0.3375760316848755\n",
            "------------\n",
            "epoch: 41\n",
            "loss: 0.40871182084083557\n",
            "------------\n",
            "epoch: 42\n",
            "loss: 0.1608981043100357\n",
            "------------\n",
            "epoch: 43\n",
            "loss: 0.18265745043754578\n",
            "------------\n",
            "epoch: 44\n",
            "loss: 0.30311155319213867\n",
            "------------\n",
            "epoch: 45\n",
            "loss: 0.27589964866638184\n",
            "------------\n",
            "epoch: 46\n",
            "loss: 0.7048150300979614\n",
            "------------\n",
            "epoch: 47\n",
            "loss: 0.3797930181026459\n",
            "------------\n",
            "epoch: 48\n",
            "loss: 0.24589285254478455\n",
            "------------\n",
            "epoch: 49\n",
            "loss: 0.19522514939308167\n",
            "------------\n",
            "epoch: 50\n",
            "loss: 0.0978889986872673\n",
            "------------\n",
            "epoch: 51\n",
            "loss: 0.281919926404953\n",
            "------------\n",
            "epoch: 52\n",
            "loss: 0.15540343523025513\n",
            "------------\n",
            "epoch: 53\n",
            "loss: 0.128669872879982\n",
            "------------\n",
            "epoch: 54\n",
            "loss: 0.0828632265329361\n",
            "------------\n",
            "epoch: 55\n",
            "loss: 0.1447225660085678\n",
            "------------\n",
            "epoch: 56\n",
            "loss: 0.06445186585187912\n",
            "------------\n",
            "epoch: 57\n",
            "loss: 0.09334143996238708\n",
            "------------\n",
            "epoch: 58\n",
            "loss: 0.09532924741506577\n",
            "------------\n",
            "epoch: 59\n",
            "loss: 0.12305930256843567\n",
            "------------\n",
            "epoch: 60\n",
            "loss: 0.12256860733032227\n",
            "------------\n",
            "epoch: 61\n",
            "loss: 0.04188583791255951\n",
            "------------\n",
            "epoch: 62\n",
            "loss: 0.04891738295555115\n",
            "------------\n",
            "epoch: 63\n",
            "loss: 0.024472033604979515\n",
            "------------\n",
            "epoch: 64\n",
            "loss: 0.04688701778650284\n",
            "------------\n",
            "epoch: 65\n",
            "loss: 0.034451961517333984\n",
            "------------\n",
            "epoch: 66\n",
            "loss: 0.10479854047298431\n",
            "------------\n",
            "epoch: 67\n",
            "loss: 0.03297846019268036\n",
            "------------\n",
            "epoch: 68\n",
            "loss: 0.03015352413058281\n",
            "------------\n",
            "epoch: 69\n",
            "loss: 0.047593481838703156\n",
            "------------\n",
            "epoch: 70\n",
            "loss: 0.03258611261844635\n",
            "------------\n",
            "epoch: 71\n",
            "loss: 0.024487856775522232\n",
            "------------\n",
            "epoch: 72\n",
            "loss: 0.04566822573542595\n",
            "------------\n",
            "epoch: 73\n",
            "loss: 0.053356364369392395\n",
            "------------\n",
            "epoch: 74\n",
            "loss: 0.02885257825255394\n",
            "------------\n",
            "epoch: 75\n",
            "loss: 0.023182326927781105\n",
            "------------\n",
            "epoch: 76\n",
            "loss: 0.03666042909026146\n",
            "------------\n",
            "epoch: 77\n",
            "loss: 0.027112048119306564\n",
            "------------\n",
            "epoch: 78\n",
            "loss: 0.03194517269730568\n",
            "------------\n",
            "epoch: 79\n",
            "loss: 0.007430102210491896\n",
            "------------\n",
            "epoch: 80\n",
            "loss: 0.01511067058891058\n",
            "------------\n",
            "epoch: 81\n",
            "loss: 0.023086562752723694\n",
            "------------\n",
            "epoch: 82\n",
            "loss: 0.02932506799697876\n",
            "------------\n",
            "epoch: 83\n",
            "loss: 0.012124329805374146\n",
            "------------\n",
            "epoch: 84\n",
            "loss: 0.014777332544326782\n",
            "------------\n",
            "epoch: 85\n",
            "loss: 0.006658080965280533\n",
            "------------\n",
            "epoch: 86\n",
            "loss: 0.025803986936807632\n",
            "------------\n",
            "epoch: 87\n",
            "loss: 0.011477910913527012\n",
            "------------\n",
            "epoch: 88\n",
            "loss: 0.009341243654489517\n",
            "------------\n",
            "epoch: 89\n",
            "loss: 0.005128823220729828\n",
            "------------\n",
            "epoch: 90\n",
            "loss: 0.009252996183931828\n",
            "------------\n",
            "epoch: 91\n",
            "loss: 0.015333597548305988\n",
            "------------\n",
            "epoch: 92\n",
            "loss: 0.025779856368899345\n",
            "------------\n",
            "epoch: 93\n",
            "loss: 0.00803608912974596\n",
            "------------\n",
            "epoch: 94\n",
            "loss: 0.007484606467187405\n",
            "------------\n",
            "epoch: 95\n",
            "loss: 0.010453476570546627\n",
            "------------\n",
            "epoch: 96\n",
            "loss: 0.007694601081311703\n",
            "------------\n",
            "epoch: 97\n",
            "loss: 0.011300776153802872\n",
            "------------\n",
            "epoch: 98\n",
            "loss: 0.009411264210939407\n",
            "------------\n",
            "epoch: 99\n",
            "loss: 0.004356078337877989\n",
            "------------\n",
            "final loss: 0.004356078337877989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEy1yLMGwYkj"
      },
      "source": [
        "X_test, y_test = data_test.get_data()\n",
        "trained_net = trained_net.to(torch.device('cpu'))\n",
        "pred = trained_net(X_test)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1993m6dBDZML"
      },
      "source": [
        "accur = CNN_Model.accuracy(pred,y_test)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy6SgaKwD4T2",
        "outputId": "1c349446-e503-40f0-9c0f-7e95474d3005",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(accur)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6354166865348816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKgiZDyFEIp2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}