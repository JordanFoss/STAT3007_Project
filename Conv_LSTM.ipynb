{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conv_LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNisK2CBHpQG20iGueIoSrv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JordanFoss/STAT3007_Project/blob/main/Conv_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZWQb0ebc-fP",
        "outputId": "dcdc6f26-06f7-4462-d1db-8e2283c43a81"
      },
      "source": [
        "!git clone https://github.com/JordanFoss/STAT3007_Project.git\n",
        "%cd STAT3007_Project/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'STAT3007_Project'...\n",
            "remote: Enumerating objects: 3979, done.\u001b[K\n",
            "remote: Counting objects: 100% (257/257), done.\u001b[K\n",
            "remote: Compressing objects: 100% (205/205), done.\u001b[K\n",
            "remote: Total 3979 (delta 112), reused 169 (delta 50), pack-reused 3722\u001b[K\n",
            "Receiving objects: 100% (3979/3979), 677.11 MiB | 25.26 MiB/s, done.\n",
            "Resolving deltas: 100% (697/697), done.\n",
            "Checking out files: 100% (2854/2854), done.\n",
            "/content/STAT3007_Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEw6Ckz2dADM"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms import ToTensor\n",
        "import scipy\n",
        "import numpy as np\n",
        "import librosa\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "from librosa import display\n",
        "from torchsummary import summary\n",
        "\n",
        "from IPython.display import Audio"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0LO_f7TdtXz",
        "outputId": "252096a4-9fcb-4654-8fd2-4ae7cbdcb7a2"
      },
      "source": [
        "!pip install colorednoise as cn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting colorednoise\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/3e/85645bcaa5ba6003c6e3c650fe23c6352f7aa4a36eb1d700f3609e52963e/colorednoise-1.1.1.tar.gz\n",
            "Collecting as\n",
            "  Downloading https://files.pythonhosted.org/packages/b4/08/226c133ec497d25a63edb38527c02db093c7d89e6d4cdc91078834486a5d/as-0.1-py3-none-any.whl\n",
            "Collecting cn\n",
            "  Downloading https://files.pythonhosted.org/packages/d2/f0/37acf3f62cd9311fe8f9b373cacd77ce2ab131bc138615e7ccec8d9d793a/cn-0.0.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from colorednoise) (1.19.5)\n",
            "Building wheels for collected packages: colorednoise\n",
            "  Building wheel for colorednoise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colorednoise: filename=colorednoise-1.1.1-cp37-none-any.whl size=3958 sha256=efa52ddb673e3073dfbf929692307fa0806a3b6e687866f5905fa56a9a169abd\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/be/f3/3e7e1c80ebab3f6f0dbd3e34e787b902d2280d66706485fef4\n",
            "Successfully built colorednoise\n",
            "Installing collected packages: colorednoise, as, cn\n",
            "Successfully installed as-0.1 cn-0.0.0.0 colorednoise-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXPrJdoQdBoF"
      },
      "source": [
        "import pre_process\n",
        "import data_loading\n",
        "import CNN_Model\n",
        "from data_loading import *"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nVTA7Undqxc"
      },
      "source": [
        "X,y = data_loading.load_samples(os.getcwd())"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT0Z8Azqmk5w",
        "outputId": "997b2c19-9ad1-4cdc-d8e9-c075e24d86b5"
      },
      "source": [
        "X = torch.tensor(X)\n",
        "X = X.reshape(X.shape[0],1,X.shape[1],X.shape[2])\n",
        "y = torch.tensor(y)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_aDV5To1Zrl",
        "outputId": "746d143c-9311-416e-9ffa-1cf9ed2e767f"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([480, 1, 128, 63])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExITYlk_fHvl"
      },
      "source": [
        "cnn = CNN_Model.ConvNet()"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsFFMnZGlnNY",
        "outputId": "c1380177-82bd-4fec-bb8a-bf13db54785d"
      },
      "source": [
        "summary(cnn, (1,128,21))"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 14, 127, 19]              98\n",
            "              ReLU-2          [-1, 14, 127, 19]               0\n",
            "         MaxPool2d-3            [-1, 14, 64, 9]               0\n",
            "           Dropout-4            [-1, 14, 64, 9]               0\n",
            "            Conv2d-5            [-1, 24, 63, 7]           2,040\n",
            "              ReLU-6            [-1, 24, 63, 7]               0\n",
            "         MaxPool2d-7            [-1, 24, 32, 3]               0\n",
            "================================================================\n",
            "Total params: 2,138\n",
            "Trainable params: 2,138\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.82\n",
            "Params size (MB): 0.01\n",
            "Estimated Total Size (MB): 0.84\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv8lw7Y2mixF"
      },
      "source": [
        "# RNN combined with CNN\n",
        "class LRCN(nn.Module):\n",
        "    def __init__(self, CNN, shape = (24,32,3)):\n",
        "        super(LRCN, self).__init__()\n",
        "\n",
        "        self.cnn = CNN\n",
        "        self.shape = shape\n",
        "\n",
        "        channel, freq, times = shape\n",
        "        self.lstm_layers = nn.LSTM(freq*channel*times,256,num_layers = 2, bidirectional = True)\n",
        "        self.linear = nn.Sequential(nn.Linear(256*2, 5))\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x, step_size = 21, use_cuda = False):\n",
        "\n",
        "      if use_cuda:\n",
        "        h_t = torch.zeros(4,x.shape[0] ,256, dtype=torch.float).to(x.device)\n",
        "        c_t = torch.zeros(4,x.shape[0], 256, dtype=torch.float).to(x.device)\n",
        "\n",
        "      else:\n",
        "        h_t = torch.zeros(4,x.shape[0], 256, dtype=torch.float)\n",
        "        c_t = torch.zeros(4,x.shape[0], 256, dtype=torch.float)\n",
        "      \n",
        "      look_ahead_time = 21\n",
        "      for current_time in range(0,x.shape[-1], step_size):\n",
        "\n",
        "        x_t = x[:,:,:,current_time:current_time+look_ahead_time]\n",
        "        conv_x = self.cnn(x_t)\n",
        "\n",
        "        conv_x_flat =  self.flatten(conv_x)\n",
        "\n",
        "        conv_x_flat = conv_x_flat.reshape(1,conv_x_flat.shape[0],conv_x_flat.shape[1])\n",
        "\n",
        "        output, (h_t, c_t) = self.lstm_layers(conv_x_flat, (h_t, c_t))\n",
        "\n",
        "      decision_vec = self.linear(output[0])\n",
        "      return decision_vec"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWF9B5IYuAWl"
      },
      "source": [
        "conv_LSTM = LRCN(cnn)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws5r2SmL1DC5",
        "outputId": "2994abd5-70f3-40d3-a0d9-ec5de337f7f1"
      },
      "source": [
        "conv_LSTM(X[:30]).shape"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTScXLjNuuMO"
      },
      "source": [
        "data_sets = data_loading.load_sets(X,y,train_ratio=[0.8], seed = [10])"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxpGLfOqvcVJ"
      },
      "source": [
        "data_train, data_test = data_sets[0]"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmwjVjoKvdR6"
      },
      "source": [
        "def train_model(data_train, data_test, net, loss, nepoch ,lr = 0.01, batch_size = -1, use_cuda = False, print_output = True):\n",
        "\n",
        "  # appropriate data type for CPU or GPU\n",
        "  device = None\n",
        "  if use_cuda and torch.cuda.is_available():\n",
        "    dtype = torch.cuda.FloatTensor\n",
        "    device = torch.device(\"cuda\")\n",
        "    net = net.to(device)\n",
        "  else:\n",
        "    dtype = torch.FloatTensor\n",
        "\n",
        "  optimizer = optim.SGD(net.parameters(), lr = lr)\n",
        "  data_train = data_train.change_type(dtype)\n",
        "  data_test = data_test.change_type(dtype)\n",
        "\n",
        "  data_loader = DataLoader(data_train, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "  for epoch in range(nepoch):\n",
        "    for X_batch, y_batch in data_loader:\n",
        "      y_batch = y_batch.type(torch.LongTensor)\n",
        "      if use_cuda and device != None:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        y_batch = y_batch.type(torch.cuda.LongTensor)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # since all our values are negative, we convert them to positive\n",
        "\n",
        "\n",
        "      pred = net(X_batch, use_cuda = use_cuda)\n",
        "      Rn = loss(pred, y_batch)\n",
        "      Rn.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    if print_output:\n",
        "      print('epoch:', epoch)\n",
        "      print('loss:',Rn.item())\n",
        "      print('------------')\n",
        "\n",
        "  print('final loss:', Rn.item())\n",
        "\n",
        "  return net"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV5k0diR1TjR"
      },
      "source": [
        ""
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0csDbqOv8Fx"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS26mkHXwHpC",
        "outputId": "13603323-3b74-4d4e-a75d-b16715cf214d"
      },
      "source": [
        "nepoch = 10\n",
        "trained_net = train_model(data_train, data_test, conv_LSTM, loss, nepoch=nepoch , batch_size = 10,lr = 0.01, use_cuda = True, print_output = True)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "loss: 1.6191939115524292\n",
            "------------\n",
            "epoch: 1\n",
            "loss: 1.5839289426803589\n",
            "------------\n",
            "epoch: 2\n",
            "loss: 1.5451276302337646\n",
            "------------\n",
            "epoch: 3\n",
            "loss: 1.3351891040802002\n",
            "------------\n",
            "epoch: 4\n",
            "loss: 1.4917514324188232\n",
            "------------\n",
            "epoch: 5\n",
            "loss: 1.3749934434890747\n",
            "------------\n",
            "epoch: 6\n",
            "loss: 1.163201093673706\n",
            "------------\n",
            "epoch: 7\n",
            "loss: 1.2972311973571777\n",
            "------------\n",
            "epoch: 8\n",
            "loss: 1.4223605394363403\n",
            "------------\n",
            "epoch: 9\n",
            "loss: 1.1163952350616455\n",
            "------------\n",
            "final loss: 1.1163952350616455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEy1yLMGwYkj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}