{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conv_LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2wSjqxynrMJBtXwUKHrlQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JordanFoss/STAT3007_Project/blob/main/CNN_LSTM_Training_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVzcboCjHQG0"
      },
      "source": [
        "# Loading all the needed things\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZWQb0ebc-fP",
        "outputId": "963e9672-3dcc-4907-cfc9-9bf902926bf8"
      },
      "source": [
        "!git clone https://github.com/JordanFoss/STAT3007_Project.git\n",
        "%cd STAT3007_Project/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'STAT3007_Project'...\n",
            "remote: Enumerating objects: 4295, done.\u001b[K\n",
            "remote: Counting objects: 100% (573/573), done.\u001b[K\n",
            "remote: Compressing objects: 100% (356/356), done.\u001b[K\n",
            "remote: Total 4295 (delta 214), reused 573 (delta 214), pack-reused 3722\u001b[K\n",
            "Receiving objects: 100% (4295/4295), 973.20 MiB | 16.02 MiB/s, done.\n",
            "Resolving deltas: 100% (799/799), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgxL4OYFIIuZ"
      },
      "source": [
        "!pip install colorednoise as cn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEw6Ckz2dADM"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms import ToTensor\n",
        "import scipy\n",
        "import numpy as np\n",
        "import librosa\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "from librosa import display\n",
        "from torchsummary import summary\n",
        "import sklearn\n",
        "\n",
        "from IPython.display import Audio\n",
        "\n",
        "#\n",
        "# load our own python files\n",
        "from pre_process import *\n",
        "from data_loading import *\n",
        "from Models import *\n",
        "from Model_Functions import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npPL3e5UJgzz"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ0oSg-XI2_X"
      },
      "source": [
        "## Load Clean Data (from github repo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT0Z8Azqmk5w"
      },
      "source": [
        "X,y = load_samples(os.getcwd())\n",
        "X = torch.tensor(X)\n",
        "X = X.reshape(X.shape[0],1,X.shape[1],X.shape[2])\n",
        "y = torch.tensor(y)\n",
        "# train/test split\n",
        "data_sets = load_sets(X,y,train_ratio=[0.8], seed = [10])\n",
        "data_train, data_test = data_sets[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DapMCuqCJYKe"
      },
      "source": [
        "## Load Noisy data (from google drive)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQga1LWWJaIz"
      },
      "source": [
        "#Import all the noisy data\n",
        "noisy_data_train = np.load('/content/drive/MyDrive/STAT3007_project/train_test_split_snr40/noisy_train_snr40.npy')\n",
        "noisy_data_test = np.load('/content/drive/MyDrive/STAT3007_project/train_test_split_snr40/noisy_test_snr40.npy')\n",
        "noisy_targets_train = np.load('/content/drive/MyDrive/STAT3007_project/train_test_split_snr40/target_train_snr40.npy')\n",
        "noisy_targets_test = np.load('/content/drive/MyDrive/STAT3007_project/train_test_split_snr40/target_test_snr40.npy')\n",
        "\n",
        "noisy_data_train = noisy_data_train.reshape(noisy_data_train.shape[0],1,noisy_data_train.shape[1],noisy_data_train.shape[2])\n",
        "noisy_data_test = noisy_data_test.reshape(noisy_data_test.shape[0],1,noisy_data_test.shape[1],noisy_data_test.shape[2])\n",
        "\n",
        "noisy_data_train = torch.tensor(noisy_data_train)\n",
        "noisy_data_test = torch.tensor(noisy_data_test)\n",
        "\n",
        "#noisy_data = torch.tensor(noisy_data).reshape(noisy_data.shape[0],1,noisy_data.shape[1],noisy_data.shape[2])\n",
        "noisy_targets_train = torch.tensor(noisy_targets_train)\n",
        "noisy_targets_test = torch.tensor(noisy_targets_test)\n",
        "\n",
        "noisy_train = DatasetWrapper(noisy_data_train,noisy_targets_train)\n",
        "noisy_test = DatasetWrapper(noisy_data_test,noisy_targets_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQUV5muSKRgu"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmwjVjoKvdR6"
      },
      "source": [
        "def train_model(data_train, \n",
        "                data_test, \n",
        "                net, loss, \n",
        "                nepoch , \n",
        "                lr = 0.01, \n",
        "                batch_size = -1, \n",
        "                momentum = 0,\n",
        "                use_cuda = False, \n",
        "                print_output = True, \n",
        "                optimiser = 'SGD'):\n",
        "\n",
        "  # setting up arrays for recording\n",
        "  test_acc = []\n",
        "  avg_acc = []\n",
        "\n",
        "  test_loss = []\n",
        "  avg_loss = []\n",
        "  # appropriate data type for CPU or GPU\n",
        "  device = None\n",
        "  if use_cuda and torch.cuda.is_available():\n",
        "    dtype = torch.cuda.FloatTensor\n",
        "    device = torch.device(\"cuda\")\n",
        "    net = net.to(device)\n",
        "  else:\n",
        "    dtype = torch.FloatTensor\n",
        "\n",
        "  if optimiser == 'SGD':\n",
        "    optimizer = optim.SGD(net.parameters(), lr = lr, momentum = momentum)\n",
        "  else:\n",
        "    optimizer = optim.Adam(net.parameters(), lr = lr, momentum = momentum)\n",
        "  data_train = data_train.change_type(dtype)\n",
        "  data_test = data_test.change_type(dtype)\n",
        "\n",
        "  X_test,y_test = data_test.get_data()\n",
        "\n",
        "  y_test = y_test.type(torch.LongTensor)\n",
        "  if device != None:\n",
        "    y_test = y_test.type(torch.cuda.LongTensor)\n",
        "\n",
        "  data_loader = DataLoader(data_train, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "  for epoch in range(nepoch):\n",
        "    batch_acc = []\n",
        "    batch_loss = []\n",
        "    for X_batch, y_batch in data_loader:\n",
        "      \n",
        "\n",
        "      y_batch = y_batch.type(torch.LongTensor)\n",
        "      if use_cuda and device != None:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        y_batch = y_batch.type(torch.cuda.LongTensor)\n",
        "\n",
        "        \n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "\n",
        "      pred = net(X_batch, use_cuda = use_cuda)\n",
        "      Rn = loss(pred, y_batch)\n",
        "      accur = accuracy(pred,y_batch)\n",
        "\n",
        "      batch_acc.append(accur)\n",
        "      batch_loss.append(Rn.to(torch.device('cpu')).detach().numpy())\n",
        "\n",
        "      Rn.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "    avg_batch_loss = np.mean(batch_loss)\n",
        "    avg_batch_acc = np.mean(batch_acc)\n",
        "    avg_acc.append(avg_batch_acc)\n",
        "    avg_loss.append(avg_batch_loss)\n",
        "\n",
        "    pred = net(X_test, use_cuda = use_cuda)\n",
        "    Rn = loss(pred, y_test)\n",
        "    accur = accuracy(pred,y_test)\n",
        "    test_acc.append(accur)\n",
        "    test_loss.append(Rn.to(torch.device('cpu')).detach().numpy())\n",
        "\n",
        "\n",
        "    if print_output:\n",
        "      print('epoch:', epoch)\n",
        "      print('loss:',Rn.item())\n",
        "      print('------------')\n",
        "    \n",
        "\n",
        "  print('final loss:', Rn.item())\n",
        "\n",
        "  return net, avg_loss, avg_acc, test_loss, test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILuHvn8vFlQ6"
      },
      "source": [
        "## Clean data train/test\n",
        "* random seed = 69\n",
        "* Optimiser: SGD\n",
        "* lr: 0.01\n",
        "* epoch number: 40 \n",
        "* momentum: 0.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ4J2-lORKxI"
      },
      "source": [
        "# optimal hyperparameters:\n",
        "nepoch = 50\n",
        "lr = 0.01\n",
        "momentum = 0.2\n",
        "optimiser = 'SGD'\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# initialise model\n",
        "torch.manual_seed(69)\n",
        "CNN = ConvNet()\n",
        "conv_LSTM = LRCN(CNN)\n",
        "\n",
        "# train model\n",
        "trained_net,avg_loss, avg_acc, test_loss, test_acc = train_model(data_train, data_test, conv_LSTM, loss, nepoch=nepoch, momentum = momentum ,batch_size = 10,lr = lr, use_cuda = True, print_output = False, optimiser = optimiser)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMur38A6L7es"
      },
      "source": [
        "# test results\n",
        "X_test,y_test = data_test.get_data()\n",
        "trained_net = trained_net.to(torch.device('cpu'))\n",
        "pred = trained_net(X_test)\n",
        "y_pred = classification(pred)\n",
        "\n",
        "\n",
        "epoches = [i for i in range(nepoch)]\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(epoches,test_loss, label = 'test')\n",
        "plt.plot(epoches,avg_loss, label = 'train', color = 'r')\n",
        "plt.title('Loss over epoches')\n",
        "plt.xlabel('Epoches')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(epoches,test_acc, label = 'test')\n",
        "plt.plot(epoches,avg_acc, label = 'train', color = 'r')\n",
        "plt.title('Accuracy over epoches')\n",
        "plt.xlabel('Epoches')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ufmGOhGIVDB"
      },
      "source": [
        "\n",
        "labels = ['Calm', 'Happy', 'Sad', 'Angry', 'Suprised']\n",
        "confusion = sklearn.metrics.confusion_matrix(y_test.detach().numpy(), y_pred)\n",
        "thing = sklearn.metrics.ConfusionMatrixDisplay(confusion, display_labels=labels)\n",
        "thing.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kASO9-pOMPP7"
      },
      "source": [
        "## Noisy train/test\n",
        "* random seed = 69\n",
        "* Optimiser: SGD\n",
        "* lr: 0.01\n",
        "* epoch number: 40 \n",
        "* momentum: 0.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37pQQr6uKuKX"
      },
      "source": [
        "# hyperparameters:\n",
        "nepoch = 50\n",
        "lr = 0.01\n",
        "momentum = 0.2\n",
        "optimiser = 'SGD'\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "torch.manual_seed(69)\n",
        "CNN = ConvNet()\n",
        "conv_LSTM = LRCN(CNN)\n",
        "trained_net,avg_loss, avg_acc, test_loss, test_acc = train_model(noisy_train, noisy_test, conv_LSTM, loss, nepoch=nepoch, momentum = momentum ,batch_size = 10,lr = lr, use_cuda = True, print_output = False, optimiser = optimiser)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yuSkMD8UpRA"
      },
      "source": [
        "X_test,y_test = noisy_test.get_data()\n",
        "trained_net = trained_net.to(torch.device('cpu'))\n",
        "pred = trained_net(X_test)\n",
        "y_pred = classification(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMWpkbsUUxKU"
      },
      "source": [
        "import sklearn\n",
        "labels = ['Calm', 'Happy', 'Sad', 'Angry', 'Suprised']\n",
        "confusion = sklearn.metrics.confusion_matrix(y_test.detach().numpy(), y_pred)\n",
        "thing = sklearn.metrics.ConfusionMatrixDisplay(confusion, display_labels=labels)\n",
        "thing.plot(values_format = '.5g')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTVkWcydK5Xp"
      },
      "source": [
        "epoches = [i for i in range(nepoch)]\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(epoches,test_loss, label = 'test')\n",
        "plt.plot(epoches,avg_loss, label = 'train', color = 'r')\n",
        "plt.title('Loss over epoches')\n",
        "plt.xlabel('Epoches')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(epoches,test_acc, label = 'test')\n",
        "plt.plot(epoches,avg_acc, label = 'train', color = 'r')\n",
        "plt.title('Accuracy over epoches')\n",
        "plt.xlabel('Epoches')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KogSTew9MIfl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}