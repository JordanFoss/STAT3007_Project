{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOFYdhplLrWPmxCK6LjTeOZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JordanFoss/STAT3007_Project/blob/main/Encoder_logistic_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc_2bo5crxzH",
        "outputId": "430b081f-7421-49f5-b120-4d17d022e2c2"
      },
      "source": [
        "!git clone https://github.com/JordanFoss/STAT3007_Project.git\n",
        "%cd STAT3007_Project/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'STAT3007_Project'...\n",
            "remote: Enumerating objects: 3845, done.\u001b[K\n",
            "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 3845 (delta 46), reused 84 (delta 25), pack-reused 3722\u001b[K\n",
            "Receiving objects: 100% (3845/3845), 675.27 MiB | 31.12 MiB/s, done.\n",
            "Resolving deltas: 100% (631/631), done.\n",
            "Checking out files: 100% (2830/2830), done.\n",
            "/content/STAT3007_Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlhFyxs2K434"
      },
      "source": [
        "import librosa\n",
        "from librosa import display\n",
        "import colorednoise as cn\n",
        "import torch\n",
        "import numpy as np\n",
        "from IPython.display import Audio\n",
        "import glob\n",
        "from pre_process import *\n",
        "import os\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import scipy\n",
        "from torchsummary import summary\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1rLZwY00kJN"
      },
      "source": [
        "\n",
        "spectro_data = DatasetWrapper(X,y)\n",
        "train_size = int(X.shape[0] * 0.7)\n",
        "test_size = X.shape[0] - train_size\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "data_test, data_train = random_split(spectro_data,[test_size,train_size], generator = torch.Generator().manual_seed(10))\n",
        "nepoch = 100\n",
        "batch_size = 30\n",
        "\n",
        "torch.manual_seed(69)\n",
        "AE = Autoencoder(16)\n",
        "\n",
        "trained_net = train_model(data_train,AE, loss, nepoch = nepoch,lr = 0.01, batch_size = batch_size, use_cuda = True,print_output = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S39iQupwB1Bj"
      },
      "source": [
        "# next step: use encoder to classify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16mE47sYMMiY"
      },
      "source": [
        "# load the train feature net (encoder):\n",
        "feature_net = trained_net.get_encoder()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGc3yJnoH7om",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "655bf73e-110f-405f-d491-b64dd2b2b9b1"
      },
      "source": [
        "summary(feature_net.cuda(),(1,128,63))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 16, 126, 61]             160\n",
            "              ReLU-2          [-1, 16, 126, 61]               0\n",
            "         MaxPool2d-3           [-1, 16, 63, 30]               0\n",
            "              ReLU-4           [-1, 16, 63, 30]               0\n",
            "            Conv2d-5           [-1, 16, 61, 28]           2,320\n",
            "              ReLU-6           [-1, 16, 61, 28]               0\n",
            "         MaxPool2d-7           [-1, 16, 30, 14]               0\n",
            "            Conv2d-8           [-1, 16, 28, 12]           2,320\n",
            "              ReLU-9           [-1, 16, 28, 12]               0\n",
            "================================================================\n",
            "Total params: 4,800\n",
            "Trainable params: 4,800\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 2.89\n",
            "Params size (MB): 0.02\n",
            "Estimated Total Size (MB): 2.94\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRuBxY4IIMBp"
      },
      "source": [
        "\n",
        "\n",
        "# input: 128xtime_steps\n",
        "#output: 30x14 for 32 filters\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, input_channel,contain_linear = False, filter_num = 16):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.conv1 = nn.Conv2d(input_channel, filter_num, kernel_size = (2,3))\n",
        "        self.conv2 = nn.Sequential(nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(1,2), stride = 2),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Conv2d(filter_num, 8, kernel_size = (2,3)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(1,2), stride = 2),\n",
        "        )\n",
        "\n",
        "        self.contain_linar = contain_linear\n",
        "\n",
        "        if contain_linear:\n",
        "          self.linear = nn.Sequential(\n",
        "              nn.Linear(24*7, 1024),\n",
        "              nn.Linear(1024, 5),\n",
        "          )\n",
        "\n",
        "    def forward(self, x, inspect_feature = False):\n",
        "\n",
        "      first_layer = self.conv1(x)\n",
        "      conv_x = self.conv2(first_layer)\n",
        "\n",
        "      output_x = conv_x\n",
        "      if self.contain_linar:\n",
        "        conv_x_flat  = self.flatten(conv_x)\n",
        "        output_x = self.linear(conv_x_flat)\n",
        "      \n",
        "      if inspect_feature:\n",
        "        return first_layer,conv_x,output_x\n",
        "      return output_x"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8fUrkO8LMog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5791acbc-95aa-46f8-d586-d13a15cd61a6"
      },
      "source": [
        "summary(ConvNet(16).cuda(),(16,28,12))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 27, 10]           1,552\n",
            "              ReLU-2           [-1, 16, 27, 10]               0\n",
            "         MaxPool2d-3            [-1, 16, 14, 5]               0\n",
            "           Dropout-4            [-1, 16, 14, 5]               0\n",
            "            Conv2d-5             [-1, 8, 13, 3]             776\n",
            "              ReLU-6             [-1, 8, 13, 3]               0\n",
            "         MaxPool2d-7              [-1, 8, 7, 1]               0\n",
            "================================================================\n",
            "Total params: 2,328\n",
            "Trainable params: 2,328\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.02\n",
            "Forward/backward pass size (MB): 0.09\n",
            "Params size (MB): 0.01\n",
            "Estimated Total Size (MB): 0.12\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrZ7qUooN6vo"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yige6Md_Lora"
      },
      "source": [
        "Xc = []\n",
        "yc = []\n",
        "target_map = {'02':0,'03':1,'04':2,'05':3,'08':4}\n",
        "\n",
        "for file in glob.glob(os.getcwd() + '/sample-noisy-speech-actor-11/*.wav'):\n",
        "  name = file.split('/')[-1]\n",
        "  emotion = name.split('-')[0]\n",
        "\n",
        "  samples, sampling_rate = librosa.load(file, sr = 16000)\n",
        "  spec = data_gen(samples, sampling_rate, 2)\n",
        "\n",
        "  Xc.append(spec)\n",
        "  yc.append(target_map[emotion])\n",
        "\n",
        "Xc = torch.tensor(Xc)\n",
        "Xc = Xc.reshape(Xc.shape[0],1,Xc.shape[1],Xc.shape[2])\n",
        "\n",
        "X_feature = feature_net.to(torch.device('cpu'))(Xc)\n",
        "\n",
        "yc = torch.tensor(yc)\n",
        "yc = yc.type(torch.LongTensor)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9hErwFZsB7i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tkyz_nrqZcK"
      },
      "source": [
        "X_feature = torch.tensor(X_feature.detach().numpy())"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zYJzfvFO2jG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4afa883c-89c4-4679-f255-26a844daa24c"
      },
      "source": [
        "classification_data = DatasetWrapper(X_feature,yc)\n",
        "train_size = int(X_feature.shape[0] * 0.7)\n",
        "test_size = X_feature.shape[0] - train_size\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "data_test, data_train = random_split(classification_data,[test_size,train_size], generator = torch.Generator().manual_seed(10))\n",
        "nepoch = 100\n",
        "batch_size = 30\n",
        "\n",
        "torch.manual_seed(69)\n",
        "CNN = ConvNet(input_channel = 16, contain_linear= True).cuda()\n",
        "\n",
        "\n",
        "\n",
        "trained_net = train_model(data_train,CNN, loss, nepoch = nepoch,lr = 0.01, batch_size = batch_size, use_cuda = True,print_output = True, classification = True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "loss: 6.794913929297763e-07\n",
            "------------\n",
            "epoch: 1\n",
            "loss: 0.6743510961532593\n",
            "------------\n",
            "epoch: 2\n",
            "loss: 0.0003673128376249224\n",
            "------------\n",
            "epoch: 3\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 4\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 5\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 6\n",
            "loss: 12.359458923339844\n",
            "------------\n",
            "epoch: 7\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 8\n",
            "loss: 16.698596954345703\n",
            "------------\n",
            "epoch: 9\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 10\n",
            "loss: 72.20507049560547\n",
            "------------\n",
            "epoch: 11\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 12\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 13\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 14\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 15\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 16\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 17\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 18\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 19\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 20\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 21\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 22\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 23\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 24\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 25\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 26\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 27\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 28\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 29\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 30\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 31\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 32\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 33\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 34\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 35\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 36\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 37\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 38\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 39\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 40\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 41\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 42\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 43\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 44\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 45\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 46\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 47\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 48\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 49\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 50\n",
            "loss: 86.2164077758789\n",
            "------------\n",
            "epoch: 51\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 52\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 53\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 54\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 55\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 56\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 57\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 58\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 59\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 60\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 61\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 62\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 63\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 64\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 65\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 66\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 67\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 68\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 69\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 70\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 71\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 72\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 73\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 74\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 75\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 76\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 77\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 78\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 79\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 80\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 81\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 82\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 83\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 84\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 85\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 86\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 87\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 88\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 89\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 90\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 91\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 92\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 93\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 94\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 95\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 96\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 97\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 98\n",
            "loss: 0.0\n",
            "------------\n",
            "epoch: 99\n",
            "loss: 1291.1483154296875\n",
            "------------\n",
            "final loss: 1291.1483154296875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krn0DTnkvfMM",
        "outputId": "8de8957d-923d-4c16-d8df-a2d524f236a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_feature.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([790, 16, 28, 12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua8j5KhqwLGX"
      },
      "source": [
        "X_feature_flat = torch.flatten(X_feature,start_dim = 1)\n",
        "classification_data = DatasetWrapper(X_feature_flat,yc)\n",
        "train_size = int(X_feature.shape[0] * 0.7)\n",
        "test_size = X_feature.shape[0] - train_size\n",
        "\n",
        "data_test, data_train = random_split(classification_data,[test_size,train_size], generator = torch.Generator().manual_seed(10))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiJ3BXfYviPj"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "# building a naive bayes classifier\n",
        "def classification_model(X_train,y_train, X_test, y_test):\n",
        "  NB = MultinomialNB()\n",
        "  NB.fit(X_train,y_train)\n",
        "  y_pred = NB.predict(X_test)\n",
        "\n",
        "  # metrics\n",
        "  # count correctly classified samples\n",
        "  correct_count = np.count_nonzero(y_pred == y_test)\n",
        "  accuracy = metrics.accuracy_score(y_test,y_pred)\n",
        "  balanced_accuracy = metrics.balanced_accuracy_score(y_test,y_pred)\n",
        "\n",
        "  print('total sample counts:',y_pred.shape[0])\n",
        "  print('correct classification counts:',correct_count,'(',accuracy * 100,'%)')\n",
        "  print('{0}: {1:.1%}'.format('balanced accuracy', balanced_accuracy))\n",
        "  print('misclasification counts:',y_pred.shape[0] - correct_count,'(',(1 - accuracy)*100,'%)')\n",
        "\n",
        "  return NB"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4eJW9Ufvo9Y",
        "outputId": "74e03889-a27b-4560-f24b-c526baab7917",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_pixel_feature,training_pixel_target = data_train.dataset.get_data()\n",
        "test_pixel_feature,test_pixel_target = data_test.dataset.get_data()\n",
        "\n",
        "\n",
        "NB_pixel = classification_model(training_pixel_feature.detach().numpy(),training_pixel_target.detach().numpy(),test_pixel_feature.detach().numpy(),test_pixel_target.detach().numpy())"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total sample counts: 790\n",
            "correct classification counts: 783 ( 99.1139240506329 %)\n",
            "balanced accuracy: 99.1%\n",
            "misclasification counts: 7 ( 0.8860759493670933 %)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtpjARXtyIl6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}